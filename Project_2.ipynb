{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvbOpTo_fF3I"
      },
      "source": [
        "# Fake/Real News data analysis and classification\n",
        "Ευάγγελος Δημητριάδης</br>\n",
        "1115201700287"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDz5TmHuDrR7"
      },
      "source": [
        "# Initialisation :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brkm_hTvggcX"
      },
      "source": [
        "Give access to google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQrpebPcf2Ht"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCv23BsVCWpO"
      },
      "source": [
        "Data file locations (Indicative paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMCHnzmhCZLU"
      },
      "outputs": [],
      "source": [
        "from os import path\n",
        "\n",
        "if path.exists('./gdrive'):\n",
        "  true_data = './gdrive/MyDrive/Data/True.csv'\n",
        "  fake_data = './gdrive/MyDrive/Data/Fake.csv'\n",
        "  train_data = './gdrive/MyDrive/Data/train.csv'\n",
        "  test_data = './gdrive/MyDrive/Data/test.csv'\n",
        "elif path.exists('./drive'):\n",
        "  true_data = './drive/MyDrive/Data/True.csv'\n",
        "  fake_data = './drive/MyDrive/Data/Fake.csv'\n",
        "  train_data = './drive/MyDrive/Data/train.csv'\n",
        "  test_data = './drive/MyDrive/Data/test.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdcEBC9zYUun"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3utkIb8wYWHg"
      },
      "outputs": [],
      "source": [
        "!pip install nltk==3.4\n",
        "!pip install --upgrade gensim\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.util import ngrams\n",
        "from nltk import word_tokenize\n",
        "import numpy as np\n",
        "import statistics\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqxFSlUS9fIX"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gYx21ZK6CNY"
      },
      "source": [
        "# Data analysis:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko40ReeAaBlw"
      },
      "source": [
        "Create Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6k2uPiF9aRNe"
      },
      "outputs": [],
      "source": [
        "dft = pd.read_csv(true_data).dropna(axis='rows')\n",
        "dff = pd.read_csv(fake_data).dropna(axis='rows')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV3zhTVHdm3V"
      },
      "source": [
        "### **1.** Visualization of fake and true news titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-sYf4ecyPlq"
      },
      "outputs": [],
      "source": [
        "def preprocessing(text):\n",
        "  text=re.sub(r'[^\\w\\s]','',text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtUP8lWHfyPD"
      },
      "source": [
        "Visualise most common subjects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClIZ-gMufwk2"
      },
      "outputs": [],
      "source": [
        "#Real News\n",
        "df1=pd.DataFrame()\n",
        "df1['num_subjects'] = dft['subject'].value_counts()\n",
        "df1.plot.bar()\n",
        "\n",
        "plt.title(\"Real News most common subjects\")\n",
        "plt.show()\n",
        "\n",
        "#Fake News\n",
        "df2=pd.DataFrame()\n",
        "df2['num_subjects'] = dff['subject'].value_counts()\n",
        "df2.plot.bar()\n",
        "\n",
        "plt.title(\"Fake News most common subjects\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-QeySW0f58D"
      },
      "source": [
        "Visualise most common words found in titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIgCEty-hdyR"
      },
      "outputs": [],
      "source": [
        "#Real News\n",
        "counts_df=dft['title'].apply(preprocessing).apply(lambda x : str.lower(x)).apply(remove_stopwords).str.split(expand=True).stack().value_counts()\n",
        "counts_df=pd.DataFrame({'Unigram':counts_df.index, 'Appearances':counts_df.values})\n",
        "counts_df=counts_df.sort_values(by=['Appearances'], ascending=False)\n",
        "counts_df=counts_df[:20]\n",
        "counts_df.index = range(1, len(counts_df)+1)\n",
        "counts_df['Unigram']=counts_df['Unigram'].str.title()\n",
        "\n",
        "d = {}\n",
        "for a, x in counts_df.values:\n",
        "    d[a] = x\n",
        "\n",
        "wordcloud = WordCloud()\n",
        "wordcloud.generate_from_frequencies(frequencies=d)\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real News most common title words\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cSfw4PT7pqH"
      },
      "outputs": [],
      "source": [
        "#Fake News\n",
        "counts_df=dff['title'].apply(preprocessing).apply(lambda x : str.lower(x)).apply(remove_stopwords).str.split(expand=True).stack().value_counts()\n",
        "counts_df=pd.DataFrame({'Unigram':counts_df.index, 'Appearances':counts_df.values})\n",
        "counts_df=counts_df.sort_values(by=['Appearances'], ascending=False)\n",
        "counts_df=counts_df[:20]\n",
        "counts_df.index = range(1, len(counts_df)+1)\n",
        "counts_df['Unigram']=counts_df['Unigram'].str.title()\n",
        "\n",
        "d = {}\n",
        "for a, x in counts_df.values:\n",
        "    d[a] = x\n",
        "\n",
        "wordcloud = WordCloud()\n",
        "wordcloud.generate_from_frequencies(frequencies=d)\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake News most common title words\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW_syqn7eOcK"
      },
      "source": [
        "### **2.** Average number of characters used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGsjhlYceWmb"
      },
      "source": [
        "* Titles\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CDl6BGQdX8U"
      },
      "outputs": [],
      "source": [
        "#Real News\n",
        "df1=pd.DataFrame()\n",
        "df1['char_count'] = dft['title'].str.len()\n",
        "num_items_t=len(dft.index)\n",
        "num_characters_t=df1['char_count'].sum()\n",
        "\n",
        "#Fake News\n",
        "df2=pd.DataFrame()\n",
        "df2['char_count'] = dff['title'].str.len()\n",
        "num_items_f=len(dff.index)\n",
        "num_characters_f=df2['char_count'].sum()\n",
        "\n",
        "#Graph\n",
        "data=[num_characters_t/num_items_t,num_characters_f/num_items_f]\n",
        "avg=pd.DataFrame(data,columns = ['Average characters'])\n",
        "avg.index = ['Real News','Fake News']\n",
        "avg=avg.sort_values(by=['Average characters'], ascending=False)\n",
        "\n",
        "avg.plot.bar()\n",
        "plt.title('Average number of characters in title')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49xRF7YdekWG"
      },
      "source": [
        "* Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSv4I3VEk6gq"
      },
      "outputs": [],
      "source": [
        "#Real News\n",
        "df1=pd.DataFrame()\n",
        "df1['char_count'] = dft['text'].str.len()\n",
        "num_items_t=len(dft.index)\n",
        "num_characters_t=df1['char_count'].sum()\n",
        "\n",
        "#Fake News\n",
        "df2=pd.DataFrame()\n",
        "df2['char_count'] = dff['text'].str.len()\n",
        "num_items_f=len(dff.index)\n",
        "num_characters_f=df2['char_count'].sum()\n",
        "\n",
        "#Graph\n",
        "data=[num_characters_t/num_items_t,num_characters_f/num_items_f]\n",
        "avg=pd.DataFrame(data,columns = ['Average characters'])\n",
        "avg.index = ['Real News','Fake News']\n",
        "avg=avg.sort_values(by=['Average characters'], ascending=False)\n",
        "\n",
        "print('Text:')\n",
        "avg.plot.bar()\n",
        "plt.title('Average number of characters in text')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5U1RSmtemDH"
      },
      "source": [
        "### **3.** Number of words distribution graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4vVFwHtfs6r"
      },
      "source": [
        "* Titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuOTKHVzZpqZ"
      },
      "outputs": [],
      "source": [
        "#Real News\n",
        "df=pd.DataFrame()\n",
        "df['num_words'] = dft['title'].str.split().apply(len)\n",
        "df.hist()\n",
        "plt.title(\"Real news titles No. words distribution\")\n",
        "plt.xlabel('No.Words')\n",
        "plt.ylabel('No.Articles')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u35glaj4gJg6"
      },
      "outputs": [],
      "source": [
        "#Fake News\n",
        "df=pd.DataFrame()\n",
        "df['num_words'] = dff['title'].str.split().apply(len)\n",
        "df.hist()\n",
        "plt.title(\"Fake news titles No. words distribution\")\n",
        "plt.xlabel('No.Words')\n",
        "plt.ylabel('No.Articles')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0wKU93me7tH"
      },
      "source": [
        "* Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Puof5v3gfNeL"
      },
      "outputs": [],
      "source": [
        "#Real News\n",
        "df=pd.DataFrame()\n",
        "df['num_words'] = dft['text'].str.split().apply(len)\n",
        "df.hist()\n",
        "plt.title(\"Real news text No. words distribution\")\n",
        "plt.xlabel('No.Words')\n",
        "plt.ylabel('No.Articles')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFerhinHfNp1"
      },
      "outputs": [],
      "source": [
        "#Fake News\n",
        "df=pd.DataFrame()\n",
        "df['num_words'] = dff['text'].str.split().apply(len)\n",
        "df.hist()\n",
        "plt.title(\"Fake news text No. words distribution\")\n",
        "plt.xlabel('No.Words')\n",
        "plt.ylabel('No.Articles')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOJEBEche8-_"
      },
      "source": [
        "### **4.** Number of words distribution graph (stopwords removed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YolMDA6cyBZy"
      },
      "outputs": [],
      "source": [
        "def preprocessing(text):\n",
        "  text=re.sub(r'[^\\w\\s]','',text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8R7shl0fHJS"
      },
      "source": [
        "* Titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx6PDczwF3fU"
      },
      "outputs": [],
      "source": [
        "#Real News\n",
        "dft_sw=pd.DataFrame()\n",
        "dft_sw['title'] = dft['title'].apply(preprocessing).apply(lambda x : str.lower(x)).apply(remove_stopwords)\n",
        "\n",
        "df=pd.DataFrame()\n",
        "df['num_words'] = dft_sw['title'].str.split().apply(len)\n",
        "df.hist()\n",
        "plt.title(\"Real news titles No. words distribution (no stopwords)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpjeF_NMQiIY"
      },
      "outputs": [],
      "source": [
        "#Fake News\n",
        "dff_sw=pd.DataFrame()\n",
        "dff_sw['title'] = dff['title'].apply(preprocessing).apply(lambda x : str.lower(x)).apply(remove_stopwords)\n",
        "\n",
        "df=pd.DataFrame()\n",
        "df['num_words'] = dff_sw['title'].str.split().apply(len)\n",
        "df.hist()\n",
        "plt.title(\"Fake news titles No. words distribution (no stopwords)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSXKVLFnfIFz"
      },
      "source": [
        "* Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vugmZWUHQnhI"
      },
      "outputs": [],
      "source": [
        "#Real News\n",
        "dft_sw=pd.DataFrame()\n",
        "dft_sw['text'] = dft['text'].apply(preprocessing).apply(lambda x : str.lower(x)).apply(remove_stopwords)\n",
        "\n",
        "df=pd.DataFrame()\n",
        "df['num_words'] = dft_sw['text'].str.split().apply(len)\n",
        "df.hist()\n",
        "plt.title(\"Real news text No. words distribution (no stopwords)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AQp4d3jQxu5"
      },
      "outputs": [],
      "source": [
        "#Fake News\n",
        "dff_sw=pd.DataFrame()\n",
        "dff_sw['text'] = dff['text'].apply(preprocessing).apply(lambda x : str.lower(x)).apply(remove_stopwords)\n",
        "\n",
        "df=pd.DataFrame()\n",
        "df['num_words'] = dff_sw['text'].str.split().apply(len)\n",
        "df.hist()\n",
        "plt.title(\"Fake news text No. words distribution (no stopwords)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3zSofGCfOpE"
      },
      "source": [
        "### **5.** Most usual bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HxCDxRqhxex"
      },
      "outputs": [],
      "source": [
        "def get_ngrams(text):\n",
        "    n_grams = ngrams(word_tokenize(text), 2)\n",
        "    return [ ' '.join(grams) for grams in n_grams]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "918zLLjtvlgT"
      },
      "outputs": [],
      "source": [
        "def preprocessing(text):\n",
        "  text=re.sub(r'[^\\w\\s]','',text)\n",
        "  text=re.sub(r'\\b[a-zA-Z]\\b','',text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO7XoKbRfTBH"
      },
      "source": [
        "* Titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkI0cGfvVxdO"
      },
      "outputs": [],
      "source": [
        "#Real News\n",
        "df=dft['title'].apply(preprocessing).apply(lambda x : str.lower(x)).apply(remove_stopwords).apply(lambda row: list(get_ngrams(row)))\n",
        "df=pd.DataFrame({'Bigrams':df})\n",
        "df2 = pd.DataFrame(df.Bigrams.tolist(), index= df.index)\n",
        "df2=df2.stack().value_counts()\n",
        "\n",
        "counts_df=pd.DataFrame({'Bigram':df2.index, 'Appearances':df2.values})\n",
        "counts_df=counts_df.sort_values(by=['Appearances'], ascending=False)\n",
        "counts_df=counts_df[:20]\n",
        "counts_df.index = range(1, len(counts_df)+1)\n",
        "counts_df['Bigram']=counts_df['Bigram'].str.title()\n",
        "\n",
        "d = {}\n",
        "for a, x in counts_df.values:\n",
        "    d[a] = x\n",
        "\n",
        "wordcloud = WordCloud()\n",
        "wordcloud.generate_from_frequencies(frequencies=d)\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real News most common bigrams in titles\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osMzhAANk7fB"
      },
      "outputs": [],
      "source": [
        "#Fake News\n",
        "df=dff['title'].apply(preprocessing).apply(lambda x : str.lower(x)).apply(remove_stopwords).apply(lambda row: list(get_ngrams(row)))\n",
        "df=pd.DataFrame({'Bigrams':df})\n",
        "df2 = pd.DataFrame(df.Bigrams.tolist(), index= df.index)\n",
        "df2=df2.stack().value_counts()\n",
        "\n",
        "counts_df=pd.DataFrame({'Bigram':df2.index, 'Appearances':df2.values})\n",
        "counts_df=counts_df.sort_values(by=['Appearances'], ascending=False)\n",
        "counts_df=counts_df[:20]\n",
        "counts_df.index = range(1, len(counts_df)+1)\n",
        "counts_df['Bigram']=counts_df['Bigram'].str.title()\n",
        "\n",
        "d = {}\n",
        "for a, x in counts_df.values:\n",
        "    d[a] = x\n",
        "\n",
        "wordcloud = WordCloud()\n",
        "wordcloud.generate_from_frequencies(frequencies=d)\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake News most common bigrams in titles\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h99ggZf5fUJJ"
      },
      "source": [
        "* Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZzCUxgmlB6E"
      },
      "outputs": [],
      "source": [
        "#Real News\n",
        "df=dft['text'].apply(preprocessing).apply(lambda x : str.lower(x)).apply(remove_stopwords).apply(lambda row: list(get_ngrams(row)))\n",
        "df=pd.DataFrame({'Bigrams':df})\n",
        "df2 = pd.DataFrame(df.Bigrams.tolist(), index= df.index)\n",
        "df2=df2.stack().value_counts()\n",
        "\n",
        "counts_df=pd.DataFrame({'Bigram':df2.index, 'Appearances':df2.values})\n",
        "counts_df=counts_df.sort_values(by=['Appearances'], ascending=False)\n",
        "counts_df=counts_df[:20]\n",
        "counts_df.index = range(1, len(counts_df)+1)\n",
        "counts_df['Bigram']=counts_df['Bigram'].str.title()\n",
        "\n",
        "d = {}\n",
        "for a, x in counts_df.values:\n",
        "    d[a] = x\n",
        "\n",
        "wordcloud = WordCloud()\n",
        "wordcloud.generate_from_frequencies(frequencies=d)\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real News most common bigrams in text\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZX4rrd4lCN8"
      },
      "outputs": [],
      "source": [
        "#Fake News\n",
        "df=dff['text'].apply(preprocessing).apply(lambda x : str.lower(x)).apply(remove_stopwords).apply(lambda row: list(get_ngrams(row)))\n",
        "df=pd.DataFrame({'Bigrams':df})\n",
        "df2 = pd.DataFrame(df.Bigrams.tolist(), index= df.index)\n",
        "df2=df2.stack().value_counts()\n",
        "\n",
        "counts_df=pd.DataFrame({'Bigram':df2.index, 'Appearances':df2.values})\n",
        "counts_df=counts_df.sort_values(by=['Appearances'], ascending=False)\n",
        "counts_df=counts_df[:20]\n",
        "counts_df.index = range(1, len(counts_df)+1)\n",
        "counts_df['Bigram']=counts_df['Bigram'].str.title()\n",
        "\n",
        "d = {}\n",
        "for a, x in counts_df.values:\n",
        "    d[a] = x\n",
        "\n",
        "wordcloud = WordCloud()\n",
        "wordcloud.generate_from_frequencies(frequencies=d)\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake News most common bigrams in text\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0PZVH7Q6CdX"
      },
      "source": [
        "# Classification dataset creation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGPlFj6vpvGW"
      },
      "source": [
        "Create a csv file for training and one for testing.</br>\n",
        "Train csv will have entries from both fake and true news files with an extra column showing if the entry is true or not (1 or 0 accordingly).</br>\n",
        "The rest of the entries will be put on the test csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOargg2jBFSF"
      },
      "outputs": [],
      "source": [
        "dft = pd.read_csv(true_data)\n",
        "dff = pd.read_csv(fake_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NRMzLCE555u"
      },
      "source": [
        "###Data pre-processing/clean-up:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXL6wlXlBrpt"
      },
      "source": [
        "* Remove rows with null values\n",
        "* Remove punctiation marks\n",
        "* Remove digits\n",
        "* Make words lowercase\n",
        "* Remove stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWU0xGoMBIgH"
      },
      "outputs": [],
      "source": [
        "def preprocessing(text):\n",
        "  text=re.sub(r'[^\\w\\s]','',text)\n",
        "  text=re.sub(r'\\d+','',text)\n",
        "  return text\n",
        "\n",
        "dft['text']=dft['text'].apply(preprocessing).apply(lambda x : str.lower(x)).apply(remove_stopwords)\n",
        "dft=dft.dropna(axis='rows')\n",
        "\n",
        "dff['text']=dff['text'].apply(preprocessing).apply(lambda x : str.lower(x)).apply(remove_stopwords)\n",
        "dff=dff.dropna(axis='rows')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYztBeh88CTf"
      },
      "source": [
        "### Training and testing Dataset Creation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ioao-OUiErJ"
      },
      "outputs": [],
      "source": [
        "#Ratio of data from each file to be put on the train csv\n",
        "ratio=1/8\n",
        "\n",
        "dft[\"label\"] = 1\n",
        "dff[\"label\"] = 0\n",
        "dft = dft.sample(frac=1).reset_index(drop=True)\n",
        "dff = dff.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "df_trn=pd.DataFrame(columns=dft.columns)\n",
        "df_tst=pd.DataFrame(columns=dft.columns)\n",
        "\n",
        "cond = dft.index < round(len(dft.index)*ratio)\n",
        "rows = dft.loc[cond, :]\n",
        "df_trn = df_trn.append(rows, ignore_index=True)\n",
        "dft.drop(rows.index, inplace=True)\n",
        "\n",
        "cond =dff.index < round(len(dff.index)*ratio)\n",
        "rows = dff.loc[cond, :]\n",
        "df_trn = df_trn.append(rows, ignore_index=True)\n",
        "dff.drop(rows.index, inplace=True)\n",
        "\n",
        "df_tst=df_tst.append(dft,ignore_index=True)\n",
        "df_tst=df_tst.append(dff,ignore_index=True)\n",
        "\n",
        "df_trn = df_trn.sample(frac=1).reset_index(drop=True)\n",
        "df_tst = df_tst.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "df_trn.to_csv(train_data, index = False)\n",
        "df_tst.to_csv(test_data, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJgtxn6e6Cl2"
      },
      "source": [
        "# Classification implementation:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UmQ-ApZrO5X"
      },
      "source": [
        "Classify articles as real or fake using:\n",
        "*   Logistic Regression\n",
        "*   Naive Bayes\n",
        "*   Support Vector Machines\n",
        "*   Random Forests\n",
        "\n",
        "Evalutate each method using:\n",
        "*   Accuracy\n",
        "*   F1 Score\n",
        "\n",
        "train.csv will be used for training the models and test.csv for testing their accuracy.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDblttEq-QoI"
      },
      "outputs": [],
      "source": [
        "df_trn = pd.read_csv(train_data).dropna(axis='rows')\n",
        "df_tst = pd.read_csv(test_data).dropna(axis='rows')\n",
        "\n",
        "#Ratio of lines to be read from each file\n",
        "#Read a portion to avoid running out of RAM (files are too big)\n",
        "ratio=3/10\n",
        "df_trn=df_trn[:round(len(df_trn.index)*ratio)]\n",
        "df_tst=df_tst[:round(len(df_tst.index)*ratio)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T79Se-ndgv09"
      },
      "source": [
        "## Bag Of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7RXbh-Xgn0o"
      },
      "outputs": [],
      "source": [
        "bow_v = CountVectorizer(ngram_range=(1, 1),stop_words='english',max_df=1.0, min_df=1)\n",
        "bow_x = bow_v.fit_transform(df_trn['text'])\n",
        "features_trn=bow_x.toarray()\n",
        "\n",
        "bow_x = bow_v.transform(df_tst['text'])\n",
        "features_tst=bow_x.toarray()\n",
        "\n",
        "trainlabel = np.asarray(df_trn['label'])\n",
        "traindata = np.asarray(features_trn)\n",
        "testlabel = np.asarray(df_tst['label'])\n",
        "testdata = np.asarray(features_tst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwqR5JFwTFXu"
      },
      "source": [
        "### Classifications:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCRvSM_e_QvR"
      },
      "outputs": [],
      "source": [
        "#Logistic Regression\n",
        "model = LogisticRegression(C = 20)\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Logistic Regression\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9ui2NcOcpvW"
      },
      "outputs": [],
      "source": [
        "#Naive Bayes\n",
        "model = GaussianNB()\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Naive Bayes\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lo1xyAQ1coyX"
      },
      "outputs": [],
      "source": [
        "#Support Vector Machines\n",
        "#Using LinearSVC for better speed and accuracy\n",
        "model = LinearSVC(C=100)\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Support Vector Machines\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhh1ZyLictC5"
      },
      "outputs": [],
      "source": [
        "#Random Forest\n",
        "model = RandomForestClassifier(n_estimators=200)\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Random Forests\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMCG4sL7knBB"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBO0jhepO_HP"
      },
      "outputs": [],
      "source": [
        "tfidf_v = TfidfVectorizer(ngram_range=(1, 1),stop_words='english',max_df=1.0, min_df=1)\n",
        "tfidf_x = tfidf_v.fit_transform(df_trn['text'])\n",
        "features_trn=tfidf_x.toarray()\n",
        "\n",
        "tfidf_x = tfidf_v.transform(df_tst['text'])\n",
        "features_tst = tfidf_x.toarray()\n",
        "\n",
        "trainlabel = np.asarray(df_trn['label'])\n",
        "traindata = np.asarray(features_trn)\n",
        "testlabel = np.asarray(df_tst['label'])\n",
        "testdata = np.asarray(features_tst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AofBIzreuQN"
      },
      "source": [
        "### Classifications:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUcU8J0feuQQ"
      },
      "outputs": [],
      "source": [
        "#Logistic Regression\n",
        "model = LogisticRegression(C = 20)\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Logistic Regression\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlPHnSVHeuQR"
      },
      "outputs": [],
      "source": [
        "#Naive Bayes\n",
        "model = GaussianNB()\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Naive Bayes\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSMxxbCteuQS"
      },
      "outputs": [],
      "source": [
        "#Support Vector Machines\n",
        "#Using LinearSVC for better speed and accuracy\n",
        "model = LinearSVC(C=100)\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Support Vector Machines\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qN818dBeuQS"
      },
      "outputs": [],
      "source": [
        "#Random Forest\n",
        "model = RandomForestClassifier(n_estimators=200)\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Random Forests\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iNdf2D1kpKz"
      },
      "source": [
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1S9riPUFkxP-"
      },
      "outputs": [],
      "source": [
        "#Train\n",
        "#Word2Vec model\n",
        "tokens = [sent.lower().split() for sent in df_trn['text']]\n",
        "\n",
        "w2vmodel = Word2Vec(tokens,vector_size=100,seed=32,negative=5,sg=0,min_count=1,window=1)\n",
        "w2vmodel.build_vocab(tokens)  # prepare the model vocabulary\n",
        "w2vmodel.train(tokens, total_examples=w2vmodel.corpus_count, epochs=5); # train the model\n",
        "\n",
        "vectors=list()\n",
        "for sentence in df_trn['text']:\n",
        "  words= sentence.lower().split()\n",
        "  vectors.append([0] * 100)\n",
        "  if len(words) > 0:\n",
        "    for word in words:\n",
        "      vectors[-1]+=w2vmodel.wv[word]\n",
        "    vectors[-1]=[number / len(words) for number in vectors[-1]]\n",
        "\n",
        "trainlabel = np.asarray(df_trn['label'])\n",
        "traindata = np.asarray(vectors)\n",
        "\n",
        "for idx, val in enumerate(traindata):\n",
        "  if all(v == 0 for v in val):\n",
        "     traindata = np.delete(traindata, idx, axis=0)\n",
        "     trainlabel = np.delete(trainlabel, idx, axis=0)\n",
        "\n",
        "#Test\n",
        "#Word2Vec model\n",
        "tokens_tst = [sent.lower().split() for sent in df_tst['text']]\n",
        "\n",
        "w2vmodel_tst = Word2Vec(tokens_tst,vector_size=100,seed=32,negative=5,sg=0,min_count=1,window=1)\n",
        "w2vmodel_tst.build_vocab(tokens_tst)  # prepare the model vocabulary\n",
        "w2vmodel_tst.train(tokens_tst, total_examples=w2vmodel_tst.corpus_count, epochs=5); # train the model\n",
        "\n",
        "vectors_tst=list()\n",
        "for sentence in df_tst['text']:\n",
        "  words= sentence.lower().split()\n",
        "  vectors_tst.append([0] * 100)\n",
        "  if len(words) > 0:\n",
        "    for word in words:\n",
        "        vectors_tst[-1]+=w2vmodel_tst.wv[word]\n",
        "    vectors_tst[-1]=[number / len(words) for number in vectors_tst[-1]]\n",
        "\n",
        "testlabel = np.asarray(df_tst['label'])\n",
        "testdata = np.asarray(vectors_tst)\n",
        "\n",
        "for idx, val in enumerate(testdata):\n",
        "  if all(v == 0 for v in val):\n",
        "     testdata = np.delete(testdata, idx, axis=0)\n",
        "     testlabel = np.delete(testlabel, idx, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vV7AgFUrexby"
      },
      "source": [
        "### Classifications:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_AzOa2Dexby"
      },
      "outputs": [],
      "source": [
        "#Logistic Regression\n",
        "model = LogisticRegression(C = 20)\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Logistic Regression\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UABaVas6exbz"
      },
      "outputs": [],
      "source": [
        "#Naive Bayes\n",
        "model = GaussianNB()\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Naive Bayes\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brtZi7w3exbz"
      },
      "outputs": [],
      "source": [
        "#Support Vector Machines\n",
        "#Using LinearSVC for better speed and accuracy\n",
        "model = LinearSVC(C=100)\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Support Vector Machines\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qs9-SkdSexb0"
      },
      "outputs": [],
      "source": [
        "#Random Forest\n",
        "model = RandomForestClassifier(n_estimators=200)\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Random Forests\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGDvvpyzs5MW"
      },
      "source": [
        "## Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PutX21CtAYq"
      },
      "source": [
        "Όπως ήταν αναμενόμενο τα classification με TF-IDF είναι κατά λίγο πιο ακριβή στις προβλέψεις από αυτά με BoW.</br>\n",
        "Tα classifications με Word2Vec έχουν με διαφορά την χαμηλότερη ακρίβεια από τις τρεις μεθόδους.Αυτό γιατί χρησιμοποιήθηκαν embeddings που έγιναν trained ξεχωριστά και μόνο με τα κείμενα στο train_data και test_data αντίστοιχα.\n",
        "Αν χρησιμοποιηθούν pre-trained embeddings η ακρίβεια εκτοξεύεται και έχει την δυνατότητα να ξεπεράσει τις άλλες δύο μεθόδους αναπαράστασης (ενδεικτικά με την χρήση glove-twitter-25 η ακρίβεια ανέβηκε στο ~86%).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbAorKED6Qs5"
      },
      "source": [
        "# Optimization of classification:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zGZkdVfeuBN"
      },
      "source": [
        "TF-IDF has the best overall classification accuracy.</br>\n",
        "We are going to try to optimize the classifications further by doing further preprocessing on the data.</br>\n",
        "Preprocessing will consist of:\n",
        "*   Lemmatizing words\n",
        "*   Removing all special characters\n",
        "*   Removing single characters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XDHW9mS8Tnj"
      },
      "outputs": [],
      "source": [
        "def preprocessing(text):\n",
        "  text=re.sub(r'\\W',' ',text)\n",
        "  text=re.sub(r'\\b[a-zA-Z]\\b','',text)\n",
        "  return text\n",
        "\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    return ' '.join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])\n",
        "\n",
        "df_trn = pd.read_csv(train_data).dropna(axis='rows')[:500]\n",
        "df_tst = pd.read_csv(test_data).dropna(axis='rows')[:1000]\n",
        "\n",
        "#Ratio of lines to be read from each file\n",
        "#Read a portion to avoid running out of RAM (files are too big)\n",
        "ratio=3/10\n",
        "df_trn=df_trn[:round(len(df_trn.index)*ratio)]\n",
        "df_tst=df_tst[:round(len(df_tst.index)*ratio)]\n",
        "\n",
        "df_trn['text']=df_trn['text'].apply(preprocessing).apply(lemmatize_text)\n",
        "df_trn['text']=df_trn['text'].dropna(axis='rows')\n",
        "df_tst['text']=df_tst['text'].apply(preprocessing).apply(lemmatize_text)\n",
        "df_tst['text']=df_tst['text'].dropna(axis='rows')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vrsx-Zl_WBL"
      },
      "outputs": [],
      "source": [
        "tfidf_v = TfidfVectorizer(ngram_range=(1, 1),stop_words='english',max_df=1.0, min_df=1)\n",
        "tfidf_x = tfidf_v.fit_transform(df_trn['text'])\n",
        "features_trn=tfidf_x.toarray()\n",
        "\n",
        "tfidf_x = tfidf_v.transform(df_tst['text'])\n",
        "features_tst = tfidf_x.toarray()\n",
        "\n",
        "trainlabel = np.asarray(df_trn['label'])\n",
        "traindata = np.asarray(features_trn)\n",
        "testlabel = np.asarray(df_tst['label'])\n",
        "testdata = np.asarray(features_tst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2rXp785elVW"
      },
      "source": [
        "### Classifications:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFDTQCATelVX"
      },
      "outputs": [],
      "source": [
        "#Logistic Regression\n",
        "model = LogisticRegression(C = 20)\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Logistic Regression\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ki4SC_hfelVX"
      },
      "outputs": [],
      "source": [
        "#Naive Bayes\n",
        "model = GaussianNB()\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Naive Bayes\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrhEHKp1elVY"
      },
      "outputs": [],
      "source": [
        "#Support Vector Machines\n",
        "#Using LinearSVC for better speed and accuracy\n",
        "model = LinearSVC(C=100)\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Support Vector Machines\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeVY6WPwelVZ"
      },
      "outputs": [],
      "source": [
        "#Random Forest\n",
        "model = RandomForestClassifier(n_estimators=200)\n",
        "model.fit(traindata,trainlabel)\n",
        "\n",
        "print(\"Random Forests\")\n",
        "accuracy = model.score(testdata, testlabel)\n",
        "print(\"accuracy = \", accuracy * 100, \"%\")\n",
        "lr_pred = model.predict(testdata)\n",
        "f1_scr = f1_score(testlabel, lr_pred, average='weighted')\n",
        "print(\"f1 score = \", f1_scr * 100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl78PMMIeiLp"
      },
      "source": [
        "### Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDX4If_0C1sW"
      },
      "source": [
        "Η ακρίβεια άλλαξε ελάχιστα.\n",
        "Γενικά έχει γίνει ήδη πολύ προεπεξεργασία στα δεδομένα οπότε δεν υπάρχουν ιδιαίτερα περιθώρια βελτίωσης με περεταίρω προεπεξεργασία."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "fDz5TmHuDrR7",
        "5gYx21ZK6CNY",
        "eV3zhTVHdm3V",
        "jW_syqn7eOcK",
        "W5U1RSmtemDH",
        "rOJEBEche8-_",
        "F3zSofGCfOpE",
        "d0PZVH7Q6CdX",
        "1NRMzLCE555u",
        "pYztBeh88CTf",
        "AJgtxn6e6Cl2",
        "T79Se-ndgv09",
        "TwqR5JFwTFXu",
        "QMCG4sL7knBB",
        "7AofBIzreuQN",
        "7iNdf2D1kpKz",
        "JGDvvpyzs5MW",
        "GbAorKED6Qs5",
        "-2rXp785elVW",
        "Hl78PMMIeiLp"
      ],
      "name": "Project-2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.6.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "58bc13ec4dd135858b8220102d0ad3358f57eb64d131366ec25c4d4365eacf63"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
